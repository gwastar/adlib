#ifndef __MUTEX_INCLUDE__
#define __MUTEX_INCLUDE__

#define _GNU_SOURCE
#include <stdlib.h>
#include <stdio.h>
#include <stdbool.h>
#include <stdatomic.h>
#include <errno.h>
#include <assert.h>
#include <unistd.h>
#include <sys/syscall.h>
#include <linux/futex.h>

#ifndef futex
#define futex _futex
static int _futex(int *uaddr, int futex_op, int val,
		   const struct timespec *timeout, int *uaddr2, int val3)
{
	return syscall(SYS_futex, uaddr, futex_op, val, timeout, uaddr2, val3);
}
#endif

// #define MUTEX_OWNER

struct mutex {
	union {
		atomic_ullong locked_waiting;
		struct {
			atomic_uint locked;
			atomic_uint waiting;
		};
	};
#ifdef MUTEX_OWNER
	pthread_t owner;
	bool check_owner;
	bool recursive;
#endif
};

static_assert(sizeof(unsigned long long) == 2 * sizeof(unsigned int), "");

#ifdef MUTEX_OWNER
# define MUTEX_INITIALIZER {{0}, 0, 0, 0}
#else
# define MUTEX_INITIALIZER {0}
#endif

#ifdef MUTEX_OWNER
static void mutex_init(struct mutex *lock, bool check_owner, bool recursive)
#else
static void mutex_init(struct mutex *lock)
#endif
{
	lock->locked_waiting = 0;
#ifdef MUTEX_OWNER
	lock->owner = 0;
	lock->check_owner = check_owner;
	lock->recursive = recursive;
#endif
}

static bool mutex_trylock(struct mutex *lock)
{
#ifdef MUTEX_OWNER
	pthread_t tid = (lock->recursive || lock->check_owner) ? pthread_self() : 0;
	if (lock->recursive && lock->owner == tid) {
		unsigned int locked = atomic_load_explicit(&lock->locked, memory_order_acquire);
		locked++;
		atomic_store_explicit(&lock->locked, locked, memory_order_release);
		return true;
	}
#endif


	unsigned int expected = 0;
	if (!atomic_compare_exchange_strong_explicit(&lock->locked, &expected, 1, memory_order_acq_rel, memory_order_relaxed)) {
		return false;
	}

#ifdef MUTEX_OWNER
	lock->owner = tid;
#endif
	return true;
}

static void mutex_lock(struct mutex *lock)
{
#ifdef MUTEX_OWNER
	pthread_t tid = (lock->recursive || lock->check_owner) ? pthread_self() : 0;
	if (lock->recursive && lock->owner == tid) {
		unsigned int locked = atomic_load_explicit(&lock->locked, memory_order_acquire);
		locked++;
		atomic_store_explicit(&lock->locked, locked, memory_order_release);
		return;
	}
#endif

retry_lock:
	for (;;) {
		unsigned int expected = 0;
		if (atomic_compare_exchange_strong_explicit(&lock->locked, &expected, 1, memory_order_acq_rel, memory_order_relaxed)) {
			break;
		}

		for (unsigned int i = 0; i < 1000; i++) {
			__builtin_ia32_pause();
		}

		for (unsigned long long val = atomic_load_explicit(&lock->locked_waiting, memory_order_relaxed);
		     ; __builtin_ia32_pause()) {
			unsigned long long locked = (unsigned int)val;
			if (!locked) {
				goto retry_lock;
			}
			unsigned long long waiting = (unsigned int)(val >> (8 * sizeof(int)));
			waiting++;
			unsigned long long newval = 1 | (waiting << (8 * sizeof(int)));

			if (atomic_compare_exchange_strong_explicit(&lock->locked_waiting, &val, newval, memory_order_seq_cst, memory_order_relaxed)) {
				break;
			}
		}

		int err = futex((int *)&lock->locked, FUTEX_WAIT | FUTEX_PRIVATE_FLAG, 1, NULL, NULL, 0);
		if (err != 0 && errno != EAGAIN) {
			perror("futex() failed");
			exit(EXIT_FAILURE);
		}

		atomic_fetch_sub_explicit(&lock->waiting, 1, memory_order_relaxed);
	}
#ifdef MUTEX_OWNER
	lock->owner = tid;
#endif
}

static void mutex_unlock(struct mutex *lock)
{
#ifdef MUTEX_OWNER
	assert(lock->recursive ? atomic_load_explicit(&lock->locked, memory_order_relaxed) >= 1 :
	       atomic_load_explicit(&lock->locked, memory_order_relaxed) == 1);
#else
	assert(atomic_load_explicit(&lock->locked, memory_order_relaxed) == 1);
#endif

#ifdef MUTEX_OWNER
	pthread_t tid = (lock->recursive || lock->check_owner) ? pthread_self() : 0;
	if (lock->check_owner && lock->owner != tid) {
		fputs("ERROR: mutex_unlock was not called by mutex owner", stderr);
		exit(EXIT_FAILURE);
	}
	if (lock->recursive && lock->owner == tid) {
		unsigned int locked = atomic_load_explicit(&lock->locked, memory_order_acquire);
		if (locked > 1) {
			locked--;
			atomic_store_explicit(&lock->locked, locked, memory_order_release);
			return;
		}
	}
	lock->owner = 0;
#endif

#if 1
	atomic_store_explicit(&lock->locked, 0, memory_order_relaxed);
	atomic_thread_fence(memory_order_seq_cst);
	unsigned int waiting = atomic_load_explicit(&lock->waiting, memory_order_relaxed);
#else
	// this avoids the mfence generated by the atomic_fence above but turns out to be slower
	unsigned long long mask = (unsigned long long)(unsigned int)-1 << (8 * sizeof(int));
	unsigned long long val = atomic_fetch_and_explicit(&lock->locked_waiting, mask, memory_order_acq_rel);
	unsigned long long waiting = (unsigned int)(val >> (8 * sizeof(int)));
#endif
	if (waiting != 0) {
		int err = futex((int *)&lock->locked, FUTEX_WAKE | FUTEX_PRIVATE_FLAG, 1, NULL, NULL, 0);
		if (err < 0) {
			perror("futex() failed");
			exit(EXIT_FAILURE);
		}
	}
}

#endif
